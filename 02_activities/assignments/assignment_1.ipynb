{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927ae8f4",
   "metadata": {},
   "source": [
    "# Assignment 1 - Building a Vision Model with Keras\n",
    "\n",
    "In this assignment, you will build a simple vision model using Keras. The goal is to classify images from the Fashion MNIST dataset, which contains images of clothing items.\n",
    "\n",
    "You will:\n",
    "1. Load and inspect the Fashion MNIST dataset.\n",
    "2. Run a simple baseline model to establish a performance benchmark.\n",
    "3. Build and evaluate a simple CNN model, choosing appropriate loss and metrics.\n",
    "4. Design and run controlled experiments on one hyperparameter (e.g., number of filters, kernel size, etc.) and one regularization technique (e.g., dropout, L2 regularization).\n",
    "5. Analyze the results and visualize the model's performance.\n",
    "\n",
    "# 1. Loading and Inspecting the Dataset\n",
    "\n",
    "Fashion MNIST is a dataset of grayscale images of clothing items, with 10 classes. Each image is 28x28 pixels, like the MNIST dataset of handwritten digits. Keras provides a convenient way to load this dataset. \n",
    "\n",
    "In this section, you should:\n",
    "\n",
    "- [ ] Inspect the shapes of the training and test sets to confirm their size and structure.\n",
    "- [ ] Convert the labels to one-hot encoded format if necessary. (There is a utility function in Keras for this.)\n",
    "- [ ] Visualize a few images from the dataset to understand what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "420c7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Classes in the Fashion MNIST dataset\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6c89fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28), Training labels shape: (60000,)\n",
      "Testing data shape: (10000, 28, 28), Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shapes of the datasets\n",
    "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_test_onehot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13e100db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pixel value statistics:\n",
      "Min value: 0.0\n",
      "Max value: 1.0\n",
      "Mean value: 0.286\n",
      "Std value: 0.353\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Verify the data looks as expected\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(15):\n",
    "    idx = np.random.randint(0, len(X_train))\n",
    "    img = X_train[idx]\n",
    "    label = y_train[idx]\n",
    "\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f\"{class_names[label]}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPixel value statistics:\")\n",
    "print(f\"Min value: {X_train.min()}\")\n",
    "print(f\"Max value: {X_train.max()}\")\n",
    "print(f\"Mean value: {X_train.mean():.3f}\")\n",
    "print(f\"Std value: {X_train.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f7dd0",
   "metadata": {},
   "source": [
    "Reflection: Does the data look as expected? How is the quality of the images? Are there any issues with the dataset that you notice?\n",
    "\n",
    "The data seems to be acceptable. However, the quality of images is quite low. The images seem pixellated even at such a low resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8ad60",
   "metadata": {},
   "source": [
    "# 2. Baseline Model\n",
    "\n",
    "In this section, you will create a linear regression model as a baseline. This model will not use any convolutional layers, but it will help you understand the performance of a simple model on this dataset.\n",
    "You should:\n",
    "- [ ] Create a simple linear regression model using Keras.\n",
    "- [ ] Compile the model with an appropriate loss function and optimizer.\n",
    "- [ ] Train the model on the training set and evaluate it on the test set.\n",
    "\n",
    "A linear regression model can be created using the `Sequential` API in Keras. Using a single `Dense` layer with no activation function is equivalent to a simple linear regression model. Make sure that the number of units in the output layer matches the number of classes in the dataset.\n",
    "\n",
    "Note that for this step, we will need to use `Flatten` to convert the 2D images into 1D vectors before passing them to the model. Put a `Flatten()` layer as the first layer in your model so that the 2D image data can be flattened into 1D vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jay\\Documents\\Learning & Development\\University of Toronto\\Data Sciences Institute\\Machine Learning\\Deep Learning\\deep_learning\\deep-learning-env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\Jay\\Documents\\Learning & Development\\University of Toronto\\Data Sciences Institute\\Machine Learning\\Deep Learning\\deep_learning\\deep-learning-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> \n",
       "\n",
       " dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_16 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                      \u001b[38;5;34m7,850\u001b[0m \n",
       "\n",
       " dense_17 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                        \u001b[38;5;34m110\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,960</span> (31.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,960\u001b[0m (31.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,960</span> (31.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,960\u001b[0m (31.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1502 - loss: 8.9023 - val_accuracy: 0.1479 - val_loss: 9.5936\n",
      "Epoch 2/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1474 - loss: 9.5108 - val_accuracy: 0.1486 - val_loss: 9.8449\n",
      "Epoch 3/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1480 - loss: 9.9234 - val_accuracy: 0.1507 - val_loss: 10.0786\n",
      "Epoch 4/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1489 - loss: 10.0094 - val_accuracy: 0.1490 - val_loss: 7.7449\n",
      "Epoch 5/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1465 - loss: 9.6687 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 6/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 7/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 8/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 9/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 10/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 11/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 12/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 13/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 14/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 15/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 16/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 17/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 18/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 19/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 20/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 21/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 22/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 23/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 24/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 25/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 26/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 27/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 28/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 29/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 30/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 31/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 32/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 33/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 34/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 35/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 36/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 37/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 38/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 39/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 40/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 41/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 42/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 43/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 44/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 45/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 46/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 47/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 48/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 49/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "Epoch 50/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1447 - loss: 9.7751 - val_accuracy: 0.1466 - val_loss: 9.7708\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1466 - loss: 9.7708\n",
      "\tTest accuracy: 0.147\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Create a simple linear regression model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))  # Flatten the 28x28 images into a 784-dimensional vector\n",
    "# You can use `model.add(<layer>)` to add layers to the model\n",
    "model.add(Dense(10, input_shape=(784,)))  # Output layer with 10 classes\n",
    "model.add(Dense(10, input_shape=(784,)))  # Output layer with 10 classes\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using `model.compile()`\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with `model.fit()`\n",
    "model.fit(X_train, y_train_onehot, epochs=50, batch_size=32, validation_data=(X_test, y_test_onehot))\n",
    "\n",
    "# Evaluate the model with `model.evaluate()`\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07e9f7",
   "metadata": {},
   "source": [
    "Reflection: What is the performance of the baseline model? How does it compare to what you expected? Why do you think the performance is at this level?\n",
    "\n",
    "The performance of the baseline model is 15%. I had low expectations, but this performance is lower than expected. The performance is at this level probably because we have not used any activation layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa107b59",
   "metadata": {},
   "source": [
    "# 3. Building and Evaluating a Simple CNN Model\n",
    "\n",
    "In this section, you will build a simple Convolutional Neural Network (CNN) model using Keras. A convolutional neural network is a type of deep learning model that is particularly effective for image classification tasks. Unlike the basic neural networks we have built in the labs, CNNs can accept images as input without needing to flatten them into vectors.\n",
    "\n",
    "You should:\n",
    "- [ ] Build a simple CNN model with at least one convolutional layer (to learn spatial hierarchies in images) and one fully connected layer (to make predictions).\n",
    "- [ ] Compile the model with an appropriate loss function and metrics for a multi-class classification problem.\n",
    "- [ ] Train the model on the training set and evaluate it on the test set.\n",
    "\n",
    "Convolutional layers are designed to accept inputs with three dimensions: height, width and channels (e.g., RGB for color images). For grayscale images like those in Fashion MNIST, the input shape will be (28, 28, 1).\n",
    "\n",
    "When you progress from the convolutional layers to the fully connected layers, you will need to flatten the output of the convolutional layers. This can be done using the `Flatten` layer in Keras, which doesn't require any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3513cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
       "\n",
       " max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">692,352</span> \n",
       "\n",
       " dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m320\u001b[0m \n",
       "\n",
       " max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_20 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m692,352\u001b[0m \n",
       "\n",
       " dense_21 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                      \u001b[38;5;34m1,290\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.3982 - val_accuracy: 0.8873 - val_loss: 0.3075\n",
      "Epoch 2/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9031 - loss: 0.2679 - val_accuracy: 0.8943 - val_loss: 0.2926\n",
      "Epoch 3/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.2212 - val_accuracy: 0.9051 - val_loss: 0.2578\n",
      "Epoch 4/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.1906 - val_accuracy: 0.9026 - val_loss: 0.2682\n",
      "Epoch 5/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.1618 - val_accuracy: 0.9119 - val_loss: 0.2496\n",
      "Epoch 6/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.1387 - val_accuracy: 0.9110 - val_loss: 0.2695\n",
      "Epoch 7/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9567 - loss: 0.1179 - val_accuracy: 0.9108 - val_loss: 0.2876\n",
      "Epoch 8/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9635 - loss: 0.0990 - val_accuracy: 0.9129 - val_loss: 0.2830\n",
      "Epoch 9/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.0842 - val_accuracy: 0.9124 - val_loss: 0.3046\n",
      "Epoch 10/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9746 - loss: 0.0712 - val_accuracy: 0.9193 - val_loss: 0.3066\n",
      "Epoch 11/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.0621 - val_accuracy: 0.9150 - val_loss: 0.3313\n",
      "Epoch 12/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0507 - val_accuracy: 0.9141 - val_loss: 0.3793\n",
      "Epoch 13/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0437 - val_accuracy: 0.9144 - val_loss: 0.3680\n",
      "Epoch 14/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0407 - val_accuracy: 0.9114 - val_loss: 0.4044\n",
      "Epoch 15/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0323 - val_accuracy: 0.9106 - val_loss: 0.4400\n",
      "Epoch 16/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0295 - val_accuracy: 0.9136 - val_loss: 0.4634\n",
      "Epoch 17/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.0264 - val_accuracy: 0.9141 - val_loss: 0.4639\n",
      "Epoch 18/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0229 - val_accuracy: 0.9150 - val_loss: 0.4804\n",
      "Epoch 19/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0246 - val_accuracy: 0.9178 - val_loss: 0.4615\n",
      "Epoch 20/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0189 - val_accuracy: 0.9122 - val_loss: 0.5041\n",
      "Epoch 21/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0184 - val_accuracy: 0.9120 - val_loss: 0.5428\n",
      "Epoch 22/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9939 - loss: 0.0191 - val_accuracy: 0.9141 - val_loss: 0.5347\n",
      "Epoch 23/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0148 - val_accuracy: 0.9082 - val_loss: 0.6133\n",
      "Epoch 24/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0167 - val_accuracy: 0.9147 - val_loss: 0.6338\n",
      "Epoch 25/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0156 - val_accuracy: 0.9127 - val_loss: 0.5920\n",
      "Epoch 26/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.9121 - val_loss: 0.6147\n",
      "Epoch 27/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.9107 - val_loss: 0.6549\n",
      "Epoch 28/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0119 - val_accuracy: 0.9076 - val_loss: 0.6838\n",
      "Epoch 29/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.9098 - val_loss: 0.6330\n",
      "Epoch 30/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0137 - val_accuracy: 0.9112 - val_loss: 0.6440\n",
      "Epoch 31/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.9143 - val_loss: 0.6796\n",
      "Epoch 32/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0116 - val_accuracy: 0.9128 - val_loss: 0.7062\n",
      "Epoch 33/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9114 - val_loss: 0.7189\n",
      "Epoch 34/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9105 - val_loss: 0.7216\n",
      "Epoch 35/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9166 - val_loss: 0.7351\n",
      "Epoch 36/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0108 - val_accuracy: 0.9116 - val_loss: 0.7455\n",
      "Epoch 37/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9050 - val_loss: 0.7601\n",
      "Epoch 38/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0131 - val_accuracy: 0.9075 - val_loss: 0.7806\n",
      "Epoch 39/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.9079 - val_loss: 0.7751\n",
      "Epoch 40/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0107 - val_accuracy: 0.9083 - val_loss: 0.7641\n",
      "Epoch 41/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 0.9053 - val_loss: 0.8127\n",
      "Epoch 42/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0110 - val_accuracy: 0.9084 - val_loss: 0.8002\n",
      "Epoch 43/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9096 - val_loss: 0.8538\n",
      "Epoch 44/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9136 - val_loss: 0.7992\n",
      "Epoch 45/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0074 - val_accuracy: 0.9111 - val_loss: 0.8906\n",
      "Epoch 46/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9113 - val_loss: 0.8273\n",
      "Epoch 47/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.9047 - val_loss: 0.8797\n",
      "Epoch 48/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9114 - val_loss: 0.8515\n",
      "Epoch 49/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9118 - val_loss: 0.8745\n",
      "Epoch 50/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.9110 - val_loss: 0.8773\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.8773\n",
      "\tTest Accuracy: 0.9110 (91.10%)\n",
      "\tTest Loss: 0.8773\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Reshape the data to include the channel dimension\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten before fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_onehot, epochs=50, batch_size=32, validation_data=(X_test, y_test_onehot))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe379c",
   "metadata": {},
   "source": [
    "Reflection: Did the CNN model perform better than the baseline model? If so, by how much? What do you think contributed to this improvement?\n",
    "\n",
    "The CNN model peformed better than the baseline model. The performance increased from 15% to 91%, even with the same number of epochs. Using CNN contributed to this improvement, since the baseline is a simple linear model and does not have any activation layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e2463",
   "metadata": {},
   "source": [
    "# 3. Designing and Running Controlled Experiments\n",
    "\n",
    "In this section, you will design and run controlled experiments to improve the model's performance. You will focus on one hyperparameter and one regularization technique.\n",
    "You should:\n",
    "- [ ] Choose one hyperparameter to experiment with (e.g., number of filters, kernel size, number of layers, etc.) and one regularization technique (e.g., dropout, L2 regularization). For your hyperparameter, you should choose at least three different values to test (but there is no upper limit). For your regularization technique, simply test the presence or absence of the technique.\n",
    "- [ ] Run experiments by modifying the model architecture or hyperparameters, and evaluate the performance of each model on the test set.\n",
    "- [ ] Record the results of your experiments, including the test accuracy and any other relevant metrics.\n",
    "- [ ] Visualize the results of your experiments using plots or tables to compare the performance of different models.\n",
    "\n",
    "The best way to run your experiments is to create a `for` loop that iterates over a range of values for the hyperparameter you are testing. For example, if you are testing different numbers of filters, you can create a loop that runs the model with 32, 64, and 128 filters. Within the loop, you can compile and train the model, then evaluate it on the test set. After each iteration, you can store the results in a list or a dictionary for later analysis.\n",
    "\n",
    "Note: It's critical that you re-initialize the model (by creating a new instance of the model) before each experiment. If you don't, the model will retain the weights from the previous experiment, which can lead to misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ef096",
   "metadata": {},
   "source": [
    "Testing with a 3 * 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99d6f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jay\\Documents\\Learning & Development\\University of Toronto\\Data Sciences Institute\\Machine Learning\\Deep Learning\\deep_learning\\deep-learning-env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8285 - loss: 0.4933 - val_accuracy: 0.8552 - val_loss: 0.3958\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8855 - loss: 0.3248 - val_accuracy: 0.8898 - val_loss: 0.3126\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9002 - loss: 0.2783 - val_accuracy: 0.8938 - val_loss: 0.2994\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9110 - loss: 0.2487 - val_accuracy: 0.9028 - val_loss: 0.2769\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9197 - loss: 0.2216 - val_accuracy: 0.8994 - val_loss: 0.2858\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9284 - loss: 0.1985 - val_accuracy: 0.9069 - val_loss: 0.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9328 - loss: 0.1854 - val_accuracy: 0.9057 - val_loss: 0.2684\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1657 - val_accuracy: 0.9094 - val_loss: 0.2669\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9447 - loss: 0.1521 - val_accuracy: 0.9102 - val_loss: 0.2664\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9495 - loss: 0.1386 - val_accuracy: 0.9122 - val_loss: 0.2594\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2746\n",
      "\tTest Accuracy: 0.9046 (90.46%)\n",
      "\tTest Loss: 0.2746\n",
      "\tTotal Parameters: 693,962\n"
     ]
    }
   ],
   "source": [
    "# A. Test Hyperparameters\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7182ed",
   "metadata": {},
   "source": [
    "Testing with a 4 * 4 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22250fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8195 - loss: 0.5116 - val_accuracy: 0.8579 - val_loss: 0.3981\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8796 - loss: 0.3430 - val_accuracy: 0.8820 - val_loss: 0.3300\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8939 - loss: 0.2962 - val_accuracy: 0.8911 - val_loss: 0.3100\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.2660 - val_accuracy: 0.8926 - val_loss: 0.3005\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9119 - loss: 0.2413 - val_accuracy: 0.8930 - val_loss: 0.2924\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9211 - loss: 0.2191 - val_accuracy: 0.8957 - val_loss: 0.2898\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.2005 - val_accuracy: 0.9053 - val_loss: 0.2675\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9321 - loss: 0.1858 - val_accuracy: 0.9064 - val_loss: 0.2678\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9391 - loss: 0.1690 - val_accuracy: 0.9125 - val_loss: 0.2518\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9439 - loss: 0.1557 - val_accuracy: 0.9070 - val_loss: 0.2656\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.2758\n",
      "\tTest Accuracy: 0.9041 (90.41%)\n",
      "\tTest Loss: 0.2758\n",
      "\tTotal Parameters: 591,786\n"
     ]
    }
   ],
   "source": [
    "# A. Test Hyperparameters\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(4, 4), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5812e",
   "metadata": {},
   "source": [
    "Testing with a 5 * 5 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af97fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8287 - loss: 0.4916 - val_accuracy: 0.8724 - val_loss: 0.3664\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8831 - loss: 0.3310 - val_accuracy: 0.8849 - val_loss: 0.3283\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8985 - loss: 0.2841 - val_accuracy: 0.8974 - val_loss: 0.2901\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9079 - loss: 0.2527 - val_accuracy: 0.9068 - val_loss: 0.2699\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9167 - loss: 0.2288 - val_accuracy: 0.9039 - val_loss: 0.2690\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9223 - loss: 0.2101 - val_accuracy: 0.9054 - val_loss: 0.2715\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9308 - loss: 0.1914 - val_accuracy: 0.9096 - val_loss: 0.2588\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9385 - loss: 0.1704 - val_accuracy: 0.9104 - val_loss: 0.2587\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9428 - loss: 0.1591 - val_accuracy: 0.9096 - val_loss: 0.2688\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9460 - loss: 0.1462 - val_accuracy: 0.9116 - val_loss: 0.2610\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2747\n",
      "\tTest Accuracy: 0.9055 (90.55%)\n",
      "\tTest Loss: 0.2747\n",
      "\tTotal Parameters: 592,074\n"
     ]
    }
   ],
   "source": [
    "# A. Test Hyperparameters\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3b1e1",
   "metadata": {},
   "source": [
    "Evaluation Based on Kernel Size\n",
    "\n",
    "| Kernel Size | Accuracy (%) |\n",
    "|-------------|--------------|\n",
    "| 3 X 3       | 90.46%       |\n",
    "| 4 X 4       | 90.41%       |\n",
    "| 5 X 5       | 90.55%       |\n",
    "\n",
    "Changing the kernel size varied the accuracy slightly. However, a 5 X 5 kernel size gave the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35891f",
   "metadata": {},
   "source": [
    "10% Dropout with 3 * 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc43ac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8294 - loss: 0.4904 - val_accuracy: 0.8639 - val_loss: 0.3825\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8856 - loss: 0.3235 - val_accuracy: 0.8813 - val_loss: 0.3278\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9009 - loss: 0.2798 - val_accuracy: 0.8991 - val_loss: 0.2826\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9090 - loss: 0.2525 - val_accuracy: 0.8999 - val_loss: 0.2839\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9179 - loss: 0.2273 - val_accuracy: 0.9021 - val_loss: 0.2719\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.2106 - val_accuracy: 0.9076 - val_loss: 0.2660\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9305 - loss: 0.1906 - val_accuracy: 0.9115 - val_loss: 0.2563\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9366 - loss: 0.1759 - val_accuracy: 0.9134 - val_loss: 0.2468\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9423 - loss: 0.1612 - val_accuracy: 0.9148 - val_loss: 0.2513\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9435 - loss: 0.1505 - val_accuracy: 0.9141 - val_loss: 0.2518\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2652\n",
      "\tTest Accuracy: 0.9092 (90.92%)\n",
      "\tTest Loss: 0.2652\n",
      "\tTotal Parameters: 693,962\n"
     ]
    }
   ],
   "source": [
    "# B. Test presence or absence of regularization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Dropout(0.1))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b95392",
   "metadata": {},
   "source": [
    "20% Dropout with 3 * 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5b799d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8295 - loss: 0.4940 - val_accuracy: 0.8641 - val_loss: 0.3805\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8821 - loss: 0.3333 - val_accuracy: 0.8868 - val_loss: 0.3187\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8959 - loss: 0.2911 - val_accuracy: 0.8946 - val_loss: 0.2924\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9032 - loss: 0.2639 - val_accuracy: 0.9009 - val_loss: 0.2817\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9122 - loss: 0.2418 - val_accuracy: 0.8896 - val_loss: 0.3049\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9183 - loss: 0.2212 - val_accuracy: 0.9119 - val_loss: 0.2505\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9245 - loss: 0.2047 - val_accuracy: 0.9079 - val_loss: 0.2557\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9295 - loss: 0.1902 - val_accuracy: 0.9112 - val_loss: 0.2514\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9348 - loss: 0.1771 - val_accuracy: 0.9142 - val_loss: 0.2454\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.1670 - val_accuracy: 0.9142 - val_loss: 0.2462\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2605\n",
      "\tTest Accuracy: 0.9099 (90.99%)\n",
      "\tTest Loss: 0.2605\n",
      "\tTotal Parameters: 693,962\n"
     ]
    }
   ],
   "source": [
    "# B. Test presence or absence of regularization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Dropout(0.2))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc047d1",
   "metadata": {},
   "source": [
    "30% Dropout with 3 * 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dca6c998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8284 - loss: 0.4894 - val_accuracy: 0.8789 - val_loss: 0.3495\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8824 - loss: 0.3315 - val_accuracy: 0.8898 - val_loss: 0.3115\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8972 - loss: 0.2875 - val_accuracy: 0.8986 - val_loss: 0.2826\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9045 - loss: 0.2633 - val_accuracy: 0.8968 - val_loss: 0.2887\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9100 - loss: 0.2456 - val_accuracy: 0.9055 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9182 - loss: 0.2235 - val_accuracy: 0.9094 - val_loss: 0.2529\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9231 - loss: 0.2091 - val_accuracy: 0.8990 - val_loss: 0.2778\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9287 - loss: 0.1965 - val_accuracy: 0.9142 - val_loss: 0.2443\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9308 - loss: 0.1847 - val_accuracy: 0.9150 - val_loss: 0.2457\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9356 - loss: 0.1745 - val_accuracy: 0.9179 - val_loss: 0.2356\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2528\n",
      "\tTest Accuracy: 0.9110 (91.10%)\n",
      "\tTest Loss: 0.2528\n",
      "\tTotal Parameters: 693,962\n"
     ]
    }
   ],
   "source": [
    "# B. Test presence or absence of regularization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Dropout(0.3))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f958f0",
   "metadata": {},
   "source": [
    "40% Dropout with 3 * 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2807ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8211 - loss: 0.5141 - val_accuracy: 0.8712 - val_loss: 0.3651\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.3527 - val_accuracy: 0.8886 - val_loss: 0.3154\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8883 - loss: 0.3090 - val_accuracy: 0.8881 - val_loss: 0.3120\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8948 - loss: 0.2863 - val_accuracy: 0.8972 - val_loss: 0.2829\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9024 - loss: 0.2647 - val_accuracy: 0.8998 - val_loss: 0.2792\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9088 - loss: 0.2448 - val_accuracy: 0.9078 - val_loss: 0.2600\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.2328 - val_accuracy: 0.9067 - val_loss: 0.2601\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9184 - loss: 0.2185 - val_accuracy: 0.9132 - val_loss: 0.2453\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9217 - loss: 0.2075 - val_accuracy: 0.9107 - val_loss: 0.2526\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.1955 - val_accuracy: 0.9111 - val_loss: 0.2479\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2597\n",
      "\tTest Accuracy: 0.9078 (90.78%)\n",
      "\tTest Loss: 0.2597\n",
      "\tTotal Parameters: 693,962\n"
     ]
    }
   ],
   "source": [
    "# B. Test presence or absence of regularization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Dropout(0.4))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a85e77",
   "metadata": {},
   "source": [
    "Evaluation Based on Dropout\n",
    "\n",
    "| Dropout (%) | Accuracy (%) |\n",
    "|-------------|--------------|\n",
    "| 10          | 90.92        |\n",
    "| 20          | 90.99        |\n",
    "| 30          | 91.1         |\n",
    "| 40          | 90.78        |\n",
    "\n",
    "Increasing the dropout also increased the accuracy until 30% dropout, but dipped again at 40%. Hence, 30% dropout provides the best accuracy, amongst the values chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb426f26",
   "metadata": {},
   "source": [
    "Reflection: Report on the performance of the models you tested. Did any of the changes you made improve the model's performance? If so, which ones? What do you think contributed to these improvements? Finally, what combination of hyperparameters and regularization techniques yielded the best performance?\n",
    "\n",
    "I have tabulated above the performance with respect to both varying kernel size and dropout. Increasing the kernel size increased the accuracy, as did increasing the dropout, however, only to a limit; the accuracy started slightly reducing beyond this limit. The combination of a 5x5 kernel size and 30% dropout gives the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c43a3d",
   "metadata": {},
   "source": [
    "# 5. Training Final Model and Evaluation\n",
    "\n",
    "In this section, you will train the final model using the best hyperparameters and regularization techniques you found in the previous section. You should:\n",
    "- [ ] Compile the final model with the best hyperparameters and regularization techniques.\n",
    "- [ ] Train the final model on the training set and evaluate it on the test set.\n",
    "- [ ] Report the final model's performance on the test set, including accuracy and any other relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31f926d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8165 - loss: 0.5248 - val_accuracy: 0.8644 - val_loss: 0.3873\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8705 - loss: 0.3687 - val_accuracy: 0.8777 - val_loss: 0.3434\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8837 - loss: 0.3240 - val_accuracy: 0.8791 - val_loss: 0.3369\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8953 - loss: 0.2920 - val_accuracy: 0.8887 - val_loss: 0.3061\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2718 - val_accuracy: 0.8992 - val_loss: 0.2818\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9068 - loss: 0.2530 - val_accuracy: 0.9006 - val_loss: 0.2793\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9111 - loss: 0.2413 - val_accuracy: 0.9052 - val_loss: 0.2641\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9165 - loss: 0.2238 - val_accuracy: 0.9072 - val_loss: 0.2629\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9218 - loss: 0.2121 - val_accuracy: 0.9004 - val_loss: 0.2829\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9260 - loss: 0.1983 - val_accuracy: 0.9079 - val_loss: 0.2561\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2740\n",
      "\tTest Accuracy: 0.9034 (90.34%)\n",
      "\tTest Loss: 0.2740\n",
      "\tTotal Parameters: 592,074\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Create model\n",
    "model_test_hyper = Sequential()\n",
    "model_test_hyper.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_test_hyper.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_test_hyper.add(Dropout(0.3))\n",
    "model_test_hyper.add(Flatten())\n",
    "model_test_hyper.add(Dense(128, activation='relu'))\n",
    "model_test_hyper.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model_test_hyper.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model_test_hyper.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model_test_hyper.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "print(f\"\\tTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"\\tTest Loss: {test_loss:.4f}\")\n",
    "print(f\"\\tTotal Parameters: {model_test_hyper.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f8ebc",
   "metadata": {},
   "source": [
    "Reflection: How does the final model's performance compare to the baseline and the CNN model? What do you think contributed to the final model's performance? If you had time, what other experiments would you run to further improve the model's performance?\n",
    "\n",
    "The final model's performance is much better than the baseline version; however, the final model is similar in performance to the CNN version. The optimized kernel size and dropout rates contributed to a final model version. If I had more time, I would further vary the epoch size and hyper-parameters to seek an even more optimized set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db8512",
   "metadata": {},
   "source": [
    " **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)**  for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `23:59 PM - 26/10/2025`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb)\n",
    "    * The Lab 1 notebook (labs/lab_1.ipynb)\n",
    "    * The Lab 2 notebook (labs/lab_2.ipynb)\n",
    "    * The Lab 3 notebook (labs/lab_3.ipynb)\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/deep_learning/pull/<pr_id>`\n",
    "* Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-7-help-ml`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
